# 是否打开 undertow 日志，默认为 false
server.undertow.accesslog.enabled=false
# 设置访问日志所在目录
server.undertow.accesslog.dir=logs
# 指定工作者线程的 I/0 线程数，默认为 2 或者 CPU 的个数
server.undertow.threads.io=16
# 指定工作者线程个数，默认为 I/O 线程个数的 8 倍
server.undertow.threads.worker=120
# 设置 HTTP POST 内容的最大长度，默认不做限制
server.undertow.max-http-post-size=0
#============== kafka ===================
# 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=192.168.100.10:9092
#spring.kafka.bootstrap-servers=10.10.30.104:9092,10.10.30.105:9092,10.10.30.106:9092
spring.kafka.bootstrap-servers=10.10.30.44:9092,10.10.30.45:9092,10.10.30.46:9092
#spring.kafka.bootstrap-servers=10.60.95.128:9092,10.60.95.129:9092,10.60.95.173:9092
#spring.kafka.bootstrap-servers=10.60.96.160:9092,10.60.96.162:9092,10.60.96.163:9092
#=============== provider  =======================
spring.kafka.producer.retries=3
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
#单位ms
spring.kafka.producer.properties.linger.ms=200
spring.kafka.producer.acks=1
# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# 写入得topic
kafka.topic.name=sdk0628


server.port=7001
logging.config=classpath:logback-spring.xml
# logback控制打印日志的环境
spring.profiles.active=dev

